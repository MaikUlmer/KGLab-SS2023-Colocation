# KGLab-SS2023-Colocation

## Task description
This project is developed in the context of the summer 2023 practical lab on knowledge bases and deals with the semantification of the [co-located property](https://www.wikidata.org/wiki/Wikidata:Property_proposal/colocated_with) between a workshop and conference.  
For the detailed problem description refer to [the original problem description](https://github.com/tholzheim/kgl-exercises/wiki#task-colocation).

The purpose of this project is to consider the [CEUR Workshop Proceedings](https://ceur-ws.org/) series and use text extraction techniques to find patterns such as "Proceedings of the 3rd Wikidata Workshop 2022 **co-located with** the 21st International Semantic Web Conference (ISWC2022)" to identify a workshop co-located with a conference.
Then the corresponding entities should be identified and the property set in Wikidata, optionally creating missing entities.

## Project workflow
The given task can be partitioned into different steps:
* Retrieving CEUR-WS volumes
* Extracting co-located information
* Retrieving conference data
    * Wikidata
    * Dblp
* Matching extracted co-located information to Wikidata entities
* Linking workshops to co-located dblp entity
* Using a Neo4j graph to manage both kinds of connections
* Writing the definitive results into Wikidata

### Retrieving CEUR-WS volumes
The CEUR-WS volumes can easily be queried as a JSON response using the provided [restful API](http://cvb.bitplan.com). Querying for both the list of volumes and proceedings yields on one hand the required textual descriptions needed for extracting the co-located patterns and on the other hand useful semantic information, such as the Wikidata URI of the event of a given CEUR-WS proceeding (even if not fully complete).

### Extracting co-located information
The co-located information is usually part of some titles or subtitles of a given volume, where the conference the workshop is co-located with follows after the keyword.
Hence, for the extraction we can use simple regular expressions matching the keyword and returning the string following it.

For this purpose the keywords we have identified are:
* co-located/colocated/collocated with
* hosted by
* affiliated with
* in conjunction with
* ' @ ' (not '@' without surrounding spaces)
* part of
* affiliated with/to
* at

It is more difficult however to extract the projected attributes of the co-located conference from the matched string.
Here we combine a few different approaches, like using the 'loctime' attribute that some volumes have set indicating the time place of the event, using regex to find the short title of the conference based on two general patterns and applying natural language processing (NLP) with [Spacy](https://spacy.io/) to extract the time and place from the matched strings.

### Retrieving conference data
#### Wikidata
[Wikidata](https://www.wikidata.org/) is the target platform of this project and a semantic wiki with an underlying knowledge graph structure.
Therefore, we can query the required conference data using Wikidata's SPARQL-endpoint without having to resort to further extraction.

#### dblp
[dblp](https://dblp.org/) is a second platform specializing in computer science publications we use to generate additional structural data to later verify the co-location of two Wikidata events or supplement information about events missing in Wikidata.

dblp is partially semantified and also provides a SPARQL endpoint for queries, but unlike Wikidata, this semantification is currently only partial, such that processing the dblp results is necessary to get certain attributes that are of interest.

### Matching extracted co-located information to Wikidata entities
The main idea informing the matching process is to do it incrementally:
Certain keywords are more distinctive than others.
While a string containing 'co-located with' definitely signifies a co-location, only some strings containing 'at' do.
Hence, the previous list of keywords to match gives a priority list.
Instead of handling all the possibly conflicting attributes generated by the different keywords at once and possibly wasting a lot of NLP computation, we handle one keyword at a time, extracting the associated attributes and match the partial list of CEUR-WS extracts against the Wikidata conferences.
Once a workshop has been successfully matched, it can be removed from further consideration and the remaining workshops tried to be matched using the next keyword.

For the matching itself, we use attribute based matching.
While we are most often successful in extracting the short title, we cannot simply only use it to match against Wikidata due to the reason, that short titles are not necessarily unique.
A notable example would be the acronym **ISWC**, which is both used by the *international semantic web conference* as well as the *IEEE international symposium on wearable computers*.

Hence we require two events to match in their acronym such as *ISWC 2022* **and** an additional attribute, such as the month or the country of the event.
Since additionally some short titles may have deviations between CEUR-WS and Wikidata, we also perform a match substituting the short match by a year match plus a fuzzy match of the conference titles.
To decide title similarity in this context we use [tf-idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) via its [Scikit-Learn](https://scikit-learn.org/stable/) implementation.
